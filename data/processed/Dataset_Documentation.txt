# Dataset Documentation: Social Media Sentiment and Stock Market Panel (6-Month)

This document provides detailed descriptions for all processed datasets used in the *DSCI510 Final Project*. Each dataset originates from Reddit discussions and Yahoo Finance stock data collected between **2025-05-15 and 2025-11-15**, focusing on ten major stocks with high discussion frequency.

---

## 1. socialmediadataclean_rows_6mo.csv

### Source
Derived from Reddit posts and comments collected via the script `get_data.py` (Public JSON). Processed through `clean_social_media.py` with ticker detection and sentiment analysis.

### Purpose
Each row represents one Reddit post or comment matched to one detected stock ticker. If a post mentions multiple tickers, it appears multiple times (one per ticker). This dataset is used for micro-level analysis of sentiment and discussion content.

### Columns
| Column | Description |
|---------|--------------|
| **kind** | Type of record — either “post” or “comment.” |
| **subreddit** | Subreddit name (e.g., `r/stocks`, `r/wallstreetbets`). |
| **id** | Reddit ID of the post or comment. |
| **parent_id** | ID of the parent post (for comments only). |
| **created_utc** | UTC timestamp when the post/comment was created. |
| **author** | Reddit username of the author. |
| **score** | Reddit upvote score for the post/comment. |
| **num_comments** | Number of comments under a post (NaN for comments). |
| **title** | Post title (empty for comments). |
| **text** | Text content of the post or comment. |
| **ticker** | Stock ticker detected from the text (e.g., TSLA, AAPL). |
| **compound** | VADER compound sentiment score (-1 to +1). |
| **neg / neu / pos** | Sentiment proportions for negative, neutral, and positive tone. |
| **date_utc** | UTC date derived from `created_utc`. |

---

## 2. socialmediadataclean_daily_6mo.csv

### Source
Aggregated from `socialmediadataclean_rows_6mo.csv` by grouping on `(date_utc, ticker)`.

### Purpose
Provides a daily-level view of Reddit discussion and sentiment for each stock. Suitable for merging with daily price data or visualization of sentiment dynamics.

### Columns
| Column | Description |
|---------|--------------|
| **date_utc** | UTC date of aggregation. |
| **ticker** | Stock ticker. |
| **n_posts** | Number of Reddit posts on this date mentioning the ticker. |
| **n_comments** | Number of comments mentioning the ticker. |
| **n_total** | Total number of mentions (posts + comments). |
| **mean_compound** | Average compound sentiment score across mentions. |
| **median_compound** | Median compound sentiment score. |
| **score_weighted_compound** | Sentiment score weighted by Reddit upvote “score.” |

---

## 3. socialmediadataclean_weekly_6mo.csv

### Source
Aggregated from the daily dataset using `aggregate_weekly.py`. Weekly windows start on **Monday** (ISO week convention).

### Purpose
Smooths daily fluctuations and aligns social signals with weekly trading data, facilitating the study of medium-term sentiment effects on price movements.

### Columns
| Column | Description |
|---------|--------------|
| **ticker** | Stock ticker symbol. |
| **week_start** | Date of the Monday that marks the start of the week. |
| **n_total_week** | Total Reddit mentions for the ticker in that week. |
| **mean_compound_week** | Mean sentiment score over the week. |
| **median_compound_week** | Median sentiment score over the week. |
| **score_weighted_compound_week** | Score-weighted weekly sentiment average. |

---

## 4. socialmediadataclean_top_tickers_6mo.csv

### Source
Generated by `clean_social_media.py` based on cumulative statistics from the row-level dataset.

### Purpose
Identifies the most discussed tickers on Reddit. This file is used to select which stocks to track for price data retrieval and subsequent regression analysis.

### Columns
| Column | Description |
|---------|--------------|
| **ticker** | Stock ticker symbol. |
| **total_mentions** | Total number of Reddit posts/comments mentioning the ticker. |
| **unique_authors** | Number of unique Reddit users who mentioned the ticker. |
| **active_days** | Number of distinct days the ticker was discussed. |
| **avg_sentiment** | Mean compound sentiment across all mentions. |

---

## 5. socialmedia_price_panel_6mo.csv

### Source
Merged output created by `merge_for_model.py`, combining `socialmediadataclean_weekly_6mo.csv` and `prices_6mo.csv`.

### Purpose
Final modeling dataset used for regression, correlation, and predictive analysis. Each row represents one ticker-week observation with both **social media** and **financial market** metrics.

### Columns
| Column | Description |
|---------|--------------|
| **ticker** | Stock ticker symbol. |
| **week_start** | Monday of the corresponding trading week. |
| **mentions_week** | Number of Reddit mentions during the week. |
| **sentiment_mean_w** | Mean sentiment score in that week. |
| **sentiment_score_weighted_w** | Score-weighted weekly sentiment. |
| **weekly_close** | Weekly closing price (end of week). |
| **weekly_volume** | Weekly trading volume (sum or average of daily volume). |
| **weekly_return** | Percentage change of weekly closing price vs. previous week. |
| **next_week_return** | Forward-looking return for the next week (target variable). |
| **abnormal_volume** | Deviation of weekly volume from rolling average (volume anomaly). |
| **z_return** | Standardized (z-scored) next_week_return. |

---

## Overall Data Flow Summary

1. **Reddit Raw → Cleaned (Row-Level)** → Sentiment scoring and ticker tagging (`clean_social_media.py`)
2. **Daily Aggregation** → Aggregate by date and ticker
3. **Weekly Aggregation** → Aggregate to week-level for modeling
4. **Merge with Prices** → Add stock market metrics, compute targets (`merge_for_model.py`)
5. **Final Modeling Panel** → Weekly observations ready for regression or forecasting

---

## Citation
All Reddit data are public and anonymized; financial data are sourced from Yahoo Finance via the `yfinance` API.
